{% extends "layout_tpnd.html" %}

{% block subsubheader %}
   <meta name="description" content="Tutorial: Twisted producer-consumer pattern and streaming data processing with AutobahnPython.">
   <link rel="stylesheet" href="{{ url_for('static', filename='css/page_tpsd_getstarted.css') }}">
{% endblock %}


{% block pagecontent %}

   <div class="pagewrapper">

      <h1>Flow Control with the Producer/Consumer Pattern</h1>

      <p>
         This tutorial is a continuation of the <a href="{{ url_for('page_python_tutorials_streaming') }}">Using the Frame-based and Streaming APIs</a> tutorial.
         It assumes you have read the latter.
      </p>

      <p>
         The tutorial demonstrates how to write WebSocket clients/servers that don't
         overwhelm the receiving side when sending data to quickly.
      </p>

      <p>
         More importantly, it demonstrates how to do this without inventing or introducing
         any kind of application-level flow-control, by using a concept built into
         Twisted: producers and consumers.
      </p>

      <p>
         You can read up about Twisted producers and consumers here:
         <a href="http://twistedmatrix.com/documents/current/core/howto/producers.html" target="_blank">
         Producers and Consumers: Efficient High-Volume Streaming
         </a>
      </p>

      <p>
         You can find all the code for this tutorial in the
         <a href="https://github.com/tavendo/AutobahnPython/tree/master/examples/websocket/streaming">source code repository</a>.
      </p>

      <h2>Prerequisites</h2>
      <p>
         For this tutorial you will need
      </p>

      <ul>
         <li>{{ autobahnpython() }} installed</li>
      </ul>

      <p>
         A guide how to setup {{ autobahnpython() }} can be found in the <a href="{{ url_for('page_python_getstarted') }}">getting started</a>.
      </p>
      <br/>


      <h2>Introduction</h2>

      <p>
         You may have noticed that in all three variants shown in the
         <a href="{{ url_for('page_python_tutorials_streaming') }}">Using the Frame-based and Streaming APIs</a> tutorial
         the generation of new data sent by the client was coupled to the reception of a digest computed by
         the server. This effectively established a kind of application-level flow control.
      </p>

      <p>
         If we had sent data just as fast as we could generate it, then server would not have been
         able to keep up, and more and more data would have been buffered on the client.
         Since our client/server pair was intended to run forever, an ever-increasing memory
         consumption on the client would be unacceptable.
      </p>

      <p>
         This application-level flow control works, but is not only ad-hoc and inconvenient,
         it also shows another undesirable effect. The client will only start to generate and
         send new data when it receives a digest message. However, at that point, the server
         has already run out of work.
      </p>

      <p>
         You can see the effect by looking at CPU consumption for
         client and server. Both will be uneven.
      </p>

      <p>
         We will now write a fourth variant of the streaming client variant of the streaming tutorial
         which does a better job at balancing this. No changes to the streaming server are necessary.
      </p>


      <h2>Streaming Producer Client</h2>

      <p>
         The streaming producer client is a variant of the streaming client. It does not rely
         any longer upon receiving digests to trigger sending of new data, but relies on
         Twisted start and stop <i>producing</i>:
      </p>

      <div class="codeex">
         <h1>Streaming Producer Client</h1>
         <pre class="brush: python; highlight: [25, 28, 42, 58, 59, 60]; toolbar: false; auto-links: false; gutter: true;">
from ranstring import randomByteString
from zope.interface import implements
from twisted.internet import reactor, interfaces
from autobahn.websocket import WebSocketProtocol, \
                               WebSocketClientFactory, \
                               WebSocketClientProtocol, \
                               connectWS

# 2^63 - This is the maximum imposed by the WS protocol
FRAME_SIZE = 0x7FFFFFFFFFFFFFFF


class RandomByteStreamProducer:
   """
   A Twisted Push Producer generating a stream of random octets sending out data
   in a WebSockets message frame.
   """
   implements(interfaces.IPushProducer)

   def __init__(self, proto):
      self.proto = proto
      self.started = False
      self.paused = False

   def pauseProducing(self):
      self.paused = True

   def resumeProducing(self):
      self.paused = False

      if not self.started:
         self.proto.beginMessage(opcode = WebSocketProtocol.MESSAGE_TYPE_BINARY)
         self.proto.beginMessageFrame(FRAME_SIZE)
         self.started = True

      while not self.paused:
         data = randomByteString(1024)
         if self.proto.sendMessageFrameData(data) <= 0:
            self.proto.beginMessageFrame(FRAME_SIZE)
            print "new frame started!"

   def stopProducing(self):
      pass


class StreamingProducerHashClientProtocol(WebSocketClientProtocol):
   """
   Streaming WebSockets client that generates stream of random octets
   sent to streaming WebSockets server, which computes a running SHA-256,
   which it will send every BATCH_SIZE octets back to us. This example
   uses a Twisted producer to produce the byte stream as fast as the
   receiver can consume, but not faster. Therefor, we don't need the
   application-level flow control as with the other examples.
   """

   def onOpen(self):
      self.count = 0
      producer = RandomByteStreamProducer(self)
      self.registerProducer(producer, True)
      producer.resumeProducing()

   def onMessage(self, message, binary):
      print "Digest for batch %d computed by server: %s" % (self.count, message)
      self.count += 1


if __name__ == '__main__':

   factory = WebSocketClientFactory("ws://localhost:9000")
   factory.protocol = StreamingProducerHashClientProtocol
   connectWS(factory)
   reactor.run()
         </pre>
      </div>

      <p>
         The client will <i>produce</i> and send new data in a loop (lines 36-40)
         as long as {{inlinecode('self.paused')}} is {{inlinecode('False')}}.
         Hence, this flag controls producing, and the flag in turn is set and reset
         within {{inlinecode('pauseProducing')}} and {{inlinecode('resumeProducing')}}.
      </p>

      <p>
         The methods {{inlinecode('pauseProducing')}} and {{inlinecode('resumeProducing')}}
         are called by Twisted in response to the receiving side (the server) being
         able to consume more data or being still busy consuming data.
      </p>

      <p>
         Twisted will detect that based on TCP backpressure, and signal this to the
         application by calling the appropriate hooks. By overriding the hooks,
         an application can then implement flow-control.
      </p>

      <p>
         When you run this client against the streaming server, you will notice
         that CPU load now remains even (non-bursty) all the time. The client
         will produce and send data exactly as fast as the server is able to
         consume, process and send back data.
      </p>


      <h2>Perspective</h2>

      <p>
         We have used the Producer-Consumer pattern here together with streaming
         data processing. The pattern can of course also be used with frame-
         or message-based processing.
      </p>

   </div> <!-- pagewrapper -->

{% endblock %}
